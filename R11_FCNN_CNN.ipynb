{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarinaWolters/Coding-Tracker/blob/master/R11_FCNN_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31Gsu_ssYQXK"
      },
      "source": [
        "# CIS-545 Recitation 9 - Neural Networks in PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are various libraries in Python to do Deep Learning such as, [PyTorch](https://pytorch.org/docs/stable/index.html), [TensorFlow](https://www.tensorflow.org/api_docs/python/tf/all_symbols) and [MxNet](https://mxnet.apache.org/versions/1.9.1/api). We can also use other libraries with built-in automatic differentiation such as [Jax](https://jax.readthedocs.io/en/latest/index.html) and its Deep Learning counterpart [Flax](https://flax.readthedocs.io/en/latest/)!"
      ],
      "metadata": {
        "id": "r7AZ5PwNlLHo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the context of this course, we will be working with PyTorch - an open-source easy to use library. "
      ],
      "metadata": {
        "id": "mieVENhRmpxF"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Rfbq1OBYWAX"
      },
      "source": [
        "## Loading Dependecies"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo"
      ],
      "metadata": {
        "id": "QguaHq5MfnGs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMyNeAcZVjif"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader\n",
        "from torchinfo import summary\n",
        "\n",
        "# Setting the device to do computations on - GPU's are generally faster!\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(torch.__version__)\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Torch Tensors and Computational Graphs\n",
        "\n",
        "PyTorch has its own data structure to facilitate computing on CPU/GPU as well use automatic differentiation for backpropagation."
      ],
      "metadata": {
        "id": "FoDz9U6_nbKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a 2D torch tensor with ones of size 5 x5\n",
        "ones_matrix = torch.ones((5, 5))\n",
        "\n",
        "# Intialize a vector with ones of size 5 x 1\n",
        "ones_vector = torch.ones((5, 1))\n"
      ],
      "metadata": {
        "id": "ISuenw__n_IJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Matrix-vector multiplication with PyTorch\n",
        "torch.matmul(ones_matrix, ones_vector)"
      ],
      "metadata": {
        "id": "nGN4-RFsoOq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ones_matrix @ ones_vector"
      ],
      "metadata": {
        "id": "SwVSXGKHo0TH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For people familiar with NumPy, there are similar functions that operate on torch tensors, to almost every function in NumPy that operate on NumPy N-d arrays.\n",
        "\n",
        "However, apart from GPU support PyTorch also offers something else that is extremely important in designing Neural Networks."
      ],
      "metadata": {
        "id": "Uf6AWuuto8R4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's consider a 5 x 5 - matrix $A$ and a 5 x 1 - vector $b$. We will compute $l$ as given:\n",
        "\n",
        "\\begin{gather*}\n",
        "  z = A \\cdot b \\\\\n",
        "  l = \\sum_{i=1}^{5} z_{i}\n",
        "\\end{gather*}\n",
        "\n",
        "We can now actually calculate gradients:\n",
        "\n",
        "\\begin{gather*}\n",
        "  \\left( \\frac{\\partial l}{\\partial b} \\right)_{i} = \\sum_{j=1}^{5} A_{ji}\n",
        "\\end{gather*}"
      ],
      "metadata": {
        "id": "8t-UzWR2r42k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_A = torch.rand((5, 5))\n",
        "tensor_A.requires_grad = True\n",
        "tensor_b = torch.rand((5, 1))\n",
        "tensor_b.requires_grad = True\n",
        "\n",
        "l_var = torch.sum(tensor_A @ tensor_b) "
      ],
      "metadata": {
        "id": "1npSKnFOqnG8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l_var.backward()"
      ],
      "metadata": {
        "id": "nGJOVwWfrPjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Torch autograd\n",
        "tensor_b.grad"
      ],
      "metadata": {
        "id": "wcUNRcjcrzWg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Expected gradient\n",
        "torch.sum(tensor_A, axis=0).detach().reshape((-1, 1))"
      ],
      "metadata": {
        "id": "Ugdj__bOsGn0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ls6hAlPGbai5"
      },
      "source": [
        "## Load the Dataset\n",
        "\n",
        "### PyTorch supports a lot of inbuilt datasets to play around with. In this recitation, we will be working with the famous [MNIST](https://en.wikipedia.org/wiki/MNIST_database#:~:text=The%20MNIST%20database%20(Modified%20National,the%20field%20of%20machine%20learning.) dataset.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTH9t9_gdybL"
      },
      "source": [
        "Documentation to load the MNIST dataset from torchvision can be found [here](https://pytorch.org/vision/stable/datasets.html).\n",
        "\n",
        "<img src='https://upload.wikimedia.org/wikipedia/commons/2/27/MnistExamples.png'>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we load the dataset from torchvision."
      ],
      "metadata": {
        "id": "G-G5bPi_crIo"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1xIADSfVzIV"
      },
      "source": [
        "mnist_dataset = torchvision.datasets.MNIST('./', download=True, train=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualising the dataset\n"
      ],
      "metadata": {
        "id": "9Cm8-do4dPm4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Look at all the class labels\n",
        "mnist_dataset.classes"
      ],
      "metadata": {
        "id": "3i-Ee9ch8c_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Looking at the images\n",
        "idx = 1000\n",
        "\n",
        "datapoint = mnist_dataset[idx]\n",
        "datapoint[0].resize([128, 128]).show()\n",
        "print('Label:', datapoint[1])"
      ],
      "metadata": {
        "id": "Aanmr8dY8MGG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Size and shape of our training data\n",
        "mnist_dataset.data.shape"
      ],
      "metadata": {
        "id": "olBob0ORLTJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transforms and Dataloaders\n",
        "\n",
        "Torchvision Transforms are a neat way to preprocess image data before passing it to our neural networks. We will be using transforms for normalizing our data and converting them to torch tensors.\n",
        "\n",
        "However, transforms are often also used for data augmentation in PyTorch. Something that you can find very useful while training Neural Networks in practice, such as in your final projects!\n",
        "\n",
        "You can find the Torchvsion documentation on transforms [here](https://pytorch.org/vision/0.9/transforms.html)."
      ],
      "metadata": {
        "id": "Cn3gtpWo9BjG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We could see what our data mean and variance are, and scale accordingly \n",
        "# - However we don't really need to worry too much about this here! Any idea why?\n",
        "\n",
        "transforms = transforms.Compose([# Fill transforms, which ones do we need?\n",
        "                                 ])"
      ],
      "metadata": {
        "id": "YEK7xoAK9PP-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1DMyS2DV1tc"
      },
      "source": [
        "# Load these datasets as we did earlier, but do remember to add the transforms above\n",
        "train_data = \n",
        "test_data = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataloaders facilitate how our network consumes the data while training. Often optimsation algorithms such as Mini-batch Gradient Descent in Deep Learning, train data in batches. We can also choose whether to shuffle the data on each iteration, "
      ],
      "metadata": {
        "id": "lIoWj-5T-7cL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Batch-size - a hyperparameter\n",
        "batch = 64\n",
        "\n",
        "# Use DataLoader class to make dataloader objects that we will use to train our models\n",
        "# use the batch size given above, and set the shuffle paramater\n",
        "train_loader = \n",
        "test_loader = "
      ],
      "metadata": {
        "id": "pP-FbQGM-5iD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A basic fully-connected Neural Network\n",
        "\n",
        "To define models in PyTorch we make use of the torch.nn module. It has all the common layers and activation functions built in. "
      ],
      "metadata": {
        "id": "y5LnoJI2Cxb-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # To flatten your images as vectors so that FCNN can read them\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        # We will be using activation functions\n",
        "        self.relu = nn.ReLU()\n",
        "        \n",
        "        # Hidden and output layers\n",
        "\n",
        "        # Add a the first input linear layer, what is the number of input dimensions? \n",
        "        # Set the number of output dimensions as 256\n",
        "        self.input = \n",
        "\n",
        "        # Add a the second linear layer, what is the number of input dimensions? \n",
        "        # Set the number of output dimensions as 64\n",
        "        self.hidden2 = \n",
        "\n",
        "        # Add a the final output layer, what is the number of input dimensions? \n",
        "        # What is the number of output dimensions for this layer?\n",
        "        self.output = \n",
        "\n",
        "    def forward(self, x):\n",
        "        outputs = nn.Sequential(self.flatten, self.hidden1, self.relu, self.hidden2, self.relu, self.output)(x)\n",
        "        return outputs"
      ],
      "metadata": {
        "id": "ekRL_w3WFPcB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model and check out its summary\n",
        "model_fcnn = FCNN().to(device)\n",
        "summary(model_fcnn, (batch, 1, 28, 28), device=device)"
      ],
      "metadata": {
        "id": "-0JW1oLMMy6G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the model:\n",
        "\n",
        "In order to train the model we need to decide on a loss function and set an optimizer. For a multi-class classification, we typically use the [Cross-Entropy loss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html)."
      ],
      "metadata": {
        "id": "WNTCkp7lG7AS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = "
      ],
      "metadata": {
        "id": "YhQ3LVsOHaEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting the Optimizer: We will use [Stochastic Gradient Descent](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html) Optimizer to optimize our loss function while training. "
      ],
      "metadata": {
        "id": "F9fKREm7Lhfy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Learning rate - another hyperparameter\n",
        "\n",
        "lr_fcnn = 0.001\n",
        "optimizer_fcnn = "
      ],
      "metadata": {
        "id": "ouByzn70LhNO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training loop:"
      ],
      "metadata": {
        "id": "51bdDhOuOyyT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs_fcnn = 10 # hyperparameter\n",
        "losses_fcnn = []\n",
        "accuracies_fcnn = []\n",
        "train_size = len(train_data)\n",
        "\n",
        "for epoch in range(num_epochs_fcnn): # Dataloader loop\n",
        "  total_loss = 0 \n",
        "  correct = 0\n",
        "  for inputs, labels in train_loader:\n",
        "    inputs = inputs.to(device) \n",
        "    labels = labels.to(device)\n",
        "\n",
        "    # Apply our model to get outputs\n",
        "    outputs = model_fcnn(input)\n",
        "\n",
        "    # Apply criterion to get loss\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    preds = torch.argmax(outputs, axis=1) # Predictions from the neural network output\n",
        "    correct += (preds == labels).sum().item()\n",
        "    total_loss += loss.item() * len(labels)\n",
        "\n",
        "    # Extremely important! - to clear out gradients from previous iterations\n",
        "    optimizer_fcnn.zero_grad()\n",
        "    loss.backward() # Calculate all the gradients\n",
        "    optimizer_fcnn.step() # Take an update step\n",
        "\n",
        "  total_loss = total_loss / train_size\n",
        "  accuracy = correct / train_size\n",
        "  losses_fcnn.append(total_loss)\n",
        "  accuracies_fcnn.append(accuracy)\n",
        "  print(\"Epoch:\", epoch+1, \", Loss:\", round(total_loss, 4), \", Training Accuracy:\", round(accuracy, 3))"
      ],
      "metadata": {
        "id": "_eUd6vprQgNv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(range(1, num_epochs_fcnn + 1), losses_fcnn)\n",
        "plt.title('Learning Curve')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Training Loss')"
      ],
      "metadata": {
        "id": "-r6wbPchbiJD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(accuracies_fcnn)"
      ],
      "metadata": {
        "id": "OrLJ6UnjYlUl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing accuracy\n",
        "test_size = len(test_data)\n",
        "correct = 0\n",
        "\n",
        "for inputs, labels in test_loader:\n",
        "  # Set inputs and outputs to the correct device\n",
        "  inputs = inputs.to(device) \n",
        "  labels = labels.to(device)\n",
        "\n",
        "  # Get model outputs\n",
        "  outputs = model_fcnn(input)\n",
        "\n",
        "  # Calculate accuracy\n",
        "  # preds = torch.argmax(outputs, axis=1) # Predictions from the neural network output\n",
        "  # correct += (preds == labels).sum().item()\n",
        "  \n",
        "  \n",
        "  \n",
        "\n",
        "test_accuracy = "
      ],
      "metadata": {
        "id": "amIrZDrVGoYQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_accuracy)"
      ],
      "metadata": {
        "id": "zoN-igUdZLip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "040YkbEDp4y8"
      },
      "source": [
        "\n",
        "## Convolutional Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtA2ULbOBliT"
      },
      "source": [
        "Convolutional Neural Networks work by applying convolutional filters to the images. The output dimension of these layers depend on the various parameters such as filter size, padding and stride.\n",
        "\n",
        "In each dimension of the image i.e. x or y:\n",
        "\n",
        "\\begin{gather*}\n",
        "  o_{x} = \\left \\lfloor \\frac{i_{x} + 2p_{x} - f_{x}}{s_{x}} \\right \\rfloor + 1\n",
        "\\end{gather*}\n",
        "\n",
        "Similarly,\n",
        "\n",
        "\\begin{gather*}\n",
        "  o_{y} = \\left \\lfloor \\frac{i_{y} + 2p_{y} - f_{y}}{s_{y}} \\right \\rfloor + 1\n",
        "\\end{gather*}\n",
        "\n",
        "Normally, we work with odd-sized, square-shaped kernels and have the padding as well as stride to have equal values in both dimensions.\n",
        "\n",
        "The depth of the output convolutional block, i.e. number of channels is given by the number of filters used in the previous convolutional layer."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining a CNN model on PyTorch"
      ],
      "metadata": {
        "id": "bLh2JWUVdwQf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You will need the documentation for [2D-convolutional layers](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html)."
      ],
      "metadata": {
        "id": "t_IISQhwHU5c"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LiBQRkpap4a8"
      },
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        \n",
        "        # Activation function\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        # Convolutional layer-1, how many input channels? (was 28 x 28 x 1)\n",
        "        # Use 16, 5x5 kernels, with same padding, and stride of 1\n",
        "        self.conv1 = \n",
        "        \n",
        "        # Pooling layer, use a 2x2 pooling layer with a stride of 2 (before 28 x 28 x 16)\n",
        "        self.maxpool = \n",
        "\n",
        "        # Output size: 16 x 14 x 14\n",
        "\n",
        "        # Convolutional layer-2: use 32, 3x3 filters, same convolution, stride of 1\n",
        "        self.conv2 = \n",
        "\n",
        "        # Maxpool\n",
        "        # Output size: 32 x 7 x 7\n",
        "        \n",
        "        # Fully connected layers\n",
        "\n",
        "        # Flatten your output\n",
        "        self.flatten = \n",
        "\n",
        "        # A final output layer, how many input and output dimensions should it have?\n",
        "        self.output = \n",
        "        \n",
        "    \n",
        "    def forward(self, x):\n",
        "        outputs = nn.Sequential(self.conv1, self.relu, self.maxpool,\n",
        "                                # Fill the rest of the layers here\n",
        "                                )(x)\n",
        "        return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize our CNN\n",
        "cnn = CNN().to(device)\n",
        "summary(cnn, (batch, 1, 28, 28))"
      ],
      "metadata": {
        "id": "NE_a1foqbV8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the CNN"
      ],
      "metadata": {
        "id": "68lnb7k0d2qZ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kP664uQDV8j-"
      },
      "source": [
        "# Sending the data to device (CPU or GPU)\n",
        "lr_cnn = 1e-4\n",
        "criterion_cnn = \n",
        "optimizer_cnn = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs_fcnn = 10 # hyperparameter\n",
        "losses_cnn = []\n",
        "accuracies_cnn = []\n",
        "train_size = len(train_data)\n",
        "\n",
        "for epoch in range(num_epochs_fcnn):\n",
        "  total_loss = 0\n",
        "  correct = 0\n",
        "\n",
        "  for inputs, labels in train_loader:\n",
        "    # Get model outputs and predictions\n",
        "\n",
        "    # Update steps for Gradient Descent\n",
        "    \n",
        "  total_loss = \n",
        "  accuracy = \n",
        "  losses_cnn.append(total_loss)\n",
        "  accuracies_cnn.append(accuracy)\n",
        "  print(\"Epoch:\", epoch+1, \", Loss:\", round(total_loss, 4), \", Training Accuracy:\", round(accuracy, 3))"
      ],
      "metadata": {
        "id": "vbkcWvzqbLN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(losses_cnn)"
      ],
      "metadata": {
        "id": "O_W2Wc81_SG3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(accuracies_cnn)"
      ],
      "metadata": {
        "id": "CeiUQMP9_W3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculating the Accuracy"
      ],
      "metadata": {
        "id": "sGbr7eP2fGzq"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVbrpBM9V_Qb"
      },
      "source": [
        "# Testing accuracy\n",
        "test_size = len(test_data)\n",
        "correct = 0\n",
        "\n",
        "for inputs, labels in test_loader:\n",
        "  # Set inputs and outputs to the correct device\n",
        "\n",
        "  # Get model outputs\n",
        "  outputs = \n",
        "\n",
        "  # Calculate accuracy\n",
        "  \n",
        "\n",
        "test_accuracy = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_accuracy)"
      ],
      "metadata": {
        "id": "Krc0rJf288XP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre-defined Models in TorchVision\n",
        "\n",
        "Torchvision provides predefined model architectures such as VGG-16, Resnet34, Resnet50 etc. You can use these model architectures and train them on new data or you can even use pretrained weights to do tasks on similar data. \n",
        "\n",
        "You can also use the pretrained models as templates and tweak them for your problem. This is called as transfer learning. It is extremely useful when we have limited data but also helps train models faster.\n",
        "\n",
        "[Here](https://github.com/vsa1920/Facial-Recognition-with-Masks-using-One-shot-learning) is an example of it from my CIS-581 project, in case you are interested in learning more on how to use pretrained models and weights. "
      ],
      "metadata": {
        "id": "0_C4zYybg8Z_"
      }
    }
  ]
}